<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <link rel="stylesheet" type="text/css" href="style.css"/>
  <script src="scripts.js"></script>

  <meta charset="utf-8">
  <meta name="description" content="Aditya Krishna Menon - Fellow, Australian National University">
  <meta name="author" content="Aditya Menon">  

  <title>Publications of Aditya Krishna Menon</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <header id="header">
    <div class="wrapper header">
      <h1 class="logo">Aditya Krishna Menon</h1>
      <nav>
          <ul>
              <li><a href="index.html#bio_anchor">Bio</a></li>
              <li><a href="index.html#interests_anchor">Research</a></li>
              <li><a href="publications.html">Publications</a></li>
              <li><a href="misc.html">Misc</a></li>
          </ul>
      </nav>
    </div>
  </header>  

  <!-- -->
  <!--   <h2>Publications <a class="toggler" href="#" id="publications_anchor" onclick="hideDiv('publications_div');">[-]</a></h2> -->

  Here is a complete list of publications by year. You can also find me on <a href=https://scholar.google.com.au/citations?user=li4mEfcAAAAJ&hl=en>Google Scholar</a>.
  <br><br>

  Inspired by <a href="http://www.cs.princeton.edu/~chazelle/linernotes.html">Bernard Chazelle's</a> wonderful idea of "liner notes" for his papers, I've included some of my own for a few papers. (These are not peer-, or even coauthor-reviewed.)  

  <!-- <div id="publications_div" style="display:none"> -->
  <div id="publications_div">
  <ul style="padding: 0em; list-style: none;">

  <!-- 
  <li> <b>TITLE</b>.
  <br>
  Aditya Krishna Menon AND FRIENDS.<br>
  To appear in <i>CONFERENCE (<b>ABBRV</b>)</i>, PLACE, YEAR.<br>
  [<a href="PDFLINK">pdf</a>]
  <br><br>
  -->

  <h3>Preprints</h3>

  <li> <b>Structured recommendation</b>.
  <br>
  Dawei Chen, Lexing Xie, Aditya Krishna Menon, and Cheng Soon Ong.<br>
  [<a href="https://arxiv.org/pdf/1706.09067">pdf</a>]
  <br><br>

  <hr>

  <h3>2019</h3>

  <li> <b>Comparative Document Collection via Classification</b>.
  <br>
  Umanga Bista, Alexander Mathews, Minjeong Shin, Aditya Krishna Menon and Lexing Xie.<br>
  To appear in <i>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, Honolulu, 2019.<br>
  [<a href="https://arxiv.org/pdf/1812.02171v1.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2018</h3>

  <li> <b>A loss framework for calibrated anomaly detection</b>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.<br>
  In <i>Advances in Neural Information Processing Systems (<b>NeurIPS</b>)</i>, Montreal, 2018.<br>
  [<a href="papers/proper-anomaly/proper-anomaly.pdf">pdf</a>]
  <br><br>

  <li> <b>The risk of trivial solutions in bipartite top ranking</b>.
  <br>
  Aditya Krishna Menon.<br>
  To appear in <i><b>Machine Learning</b></i>, 2018.<br>
  [<a href="papers/top-ranking/top-ranking.pdf">pdf</a>]
  <br><br>

  <li> <b>Learning from binary labels with instance-dependent corruption</b>.
  <br>
  Aditya Krishna Menon, Brendan van Rooyen, and Nagarajan Natarajan.<br>    
  In <i><b>Machine Learning</b></i>, Volume 107 Issue 8-10 (Special Issue on Papers from <i><b>ECML-PKDD</b></i>), 2018.<br>
  [<a href="papers/noisetron/noisetron.pdf">pdf</a>]
  <br><br>

  <li> <b>The cost of fairness in binary classification</b>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.<br>    
  In <i>Conference on Fairness, Accountability, and Transparency (<b>FAT</b>)</i>, New York City, 2018.<br>
  [<a href="https://arxiv.org/pdf/1705.09055">pdf</a>]
  <br><br>
  <!-- <br><br> -->  

  <li> <b>Proper losses for nonlinear Hawkes processes</b>.
  <br>
  Aditya Krishna Menon and Young Lee.<br>
  In <i>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, New Orleans, 2018.<br>
  [<a href="papers/proper_hawkes/proper_hawkes_aaai18.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2017</h3>

  <li> <b>f-GANs in an information geometric nutshell</b>.
  <br>
  Richard Nock, Zac Cranko, Aditya Krishna Menon, Lizhen Qu and Robert C. Williamson.<br>
  In <i>Advances in Neural Information Processing Systems (<b>NIPS</b>)</i>, Los Angeles, 2017.<br>
  [<a href="papers/vig_gan/vig_gan_nips17.pdf">pdf</a>]
  <br><br>

  <li> <b>Predicting short-term public transport demand via inhomogeneous Poisson processes</b>.
  <br>
  Aditya Krishna Menon and Young Lee.<br>
  In <i>International Conference on Information and Knowledge Management (<b>CIKM</b>)</i>, Singapore, 2017.<br>
  [<a href="papers/poisson-regression/poisson_cikm17.pdf">pdf</a>]
  <br><br>

  <li> <b>Revisiting revisits in trajectory recommendation</b>.
  <br>
  Aditya Krishna Menon, Dawei Chen, Lexing Xie and Cheng Soon Ong.<br>
  In <i>RecSys Workshop on Recommender Systems for Citizens (<b>CitRec</b>)</i>, Como, 2017.<br>
  [<a href="papers/list_viterbi/list_viterbi.pdf">pdf</a>]
  <br><br>

  <li> <b>Robust, deep and inductive anomaly detection</b>.
  <br>
  Raghavendra Chalapathy, Aditya Krishna Menon and Sanjay Chawla.<br>
  In <i>European Conference on Machine Learning (<b>ECML/PKDD</b>)</i>, Skopje, 2017.<br>
  [<a href="papers/robust_ae/robust_ae.pdf">pdf</a>]
  <br><br>

  <li> <b>Making deep neural networks robust to label noise: a loss correction approach</b>.
  <br>
  Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, Lizhen Qu.<br>
  In <i>Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, Honolulu, 2017.<br>
  [<a href="papers/deep-noise/deep-noise-paper.pdf">pdf</a>] [<a href="http://giorgiopatrini.org/assets/slides/2017_CVPR.pdf">slides</a>]
  <br><br>

  <li> <b>Low-rank linear cold-start recommendation from social data</b>.
  <br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Lexing Xie, and Darius Braziunas.<br>
  In <i>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, San Francisco, 2017.<br>
  [<a href="papers/loco/loco-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2016</h3>
   
  <li> <b>Bipartite ranking: a risk-theoretic perspective</b>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.<br>
  In <i>Journal of Machine Learning Research (<b>JMLR</b>)</i>, Volume 17, Issue 195. 2016.<br>
  [<a href="http://jmlr.org/papers/volume17/14-265/14-265.pdf">pdf</a>] [<a href="javascript:;" onclick="showDiv('liner_bipartite');">liner notes</a>]  

          <div id="liner_bipartite" style="display:none">
            <br>
            <p style='color:gray'>
            Back in 2011, months of exhaustive experimentation with AUC maximisation in the context of link prediction taught me one thing: it's hard to do better than logistic regression. I was excited when later that year, <a href=http://www.icml-2011.org/papers/567_icmlpaper.pdf>Kot≈Çowski et al.</a> gave a compelling theoretical explanation for why this might be.
            <br><br>
            When I joined NICTA in 2013, I followed a rite of passage and read Mark Reid and Bob Williamson's <a href=http://www.jmlr.org/papers/v12/reid11a.html>tour de force</a> on information, divergences, and risks. Tucked away in that paper was a mention of how the AUC related to the concepts presented. I innocently mentioned to Bob that perhaps there was more to be said here. He agreed, and suggested that I start by spelling out what was in my mind.
            <br><br>
            We never expected it would take quite that long to spell.
            [<a href="javascript:;" onclick="hideDiv('liner_bipartite');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <b>A scaled Bregman theorem with applications</b>.
  <br>
  Richard Nock, Aditya Krishna Menon and Cheng Soon Ong.<br>
  In <i>Advances in Neural Information Processing Systems (<b>NIPS</b>)</i>, Barcelona, 2016.<br>
  [<a href="https://arxiv.org/abs/1607.00360">pdf</a>]

  <br><br>

  <li> <b>Linking losses for density ratio and class-probability estimation.</b>
  <br>
  Aditya Krishna Menon and Cheng Soon Ong.<br>
  In <i>International Conference on Machine Learning (<b>ICML</b>)</i>, New York City, 2016.<br>
  [<a href="papers/density-ratio/density-ratio-paper.pdf">pdf</a>] [<a href="papers/density-ratio/density-ratio-slides.pdf">slides</a>] [<a href="papers/density-ratio/density-ratio-poster.pdf">poster</a>] [<a href="papers/density-ratio/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_density');">liner notes</a>]  

          <div id="liner_density" style="display:none">
            <br>
            <p style='color:gray'>
            Long before being introduced to proper losses, I'd known about, and completely accepted, the basic premise as to why density ratio was different to class-probability estimation: the later only <i>indirectly</i> modelled the ratio, which is generally a sub-optimal strategy. Sometime in late 2015, I re-read the cool work on <a href=http://www.jmlr.org/papers/volume10/kanamori09a/kanamori09a.pdf>LSIF</a>. This time, with link functions and partial losses fresh in my mind, I noticed that one could think of this as involving a particular proper loss plus link function. This was mildly interesting, but the point remained: using anything but the link that directly yields the density ratio must be a bad idea.
            <br><br>
            This was something of a defeat for my running theory at the time, that most everything can be attacked with some version of logistic regression. To better understand this failure mode, I was looking at Sugiyama's <a href=http://www.ism.ac.jp/editsec/aism/pdf/10463_2011_Article_343.pdf>elegant unified Bregman view</a> of density ratios. I noticed that logistic regression was mentioned, but didn't pay much attention to it; after all, the Bregman view of regret under proper losses immediately led to the KL minimisation view of logistic regression.
            <br><br>
            It was only on a re-read that I realised there was a bit more to this innocuous result: it was a statement of Bregman minimisation not to the true probability, but to the true density ratio. Now that I didn't know was true for logistic regression. Studying the surprisingly simple proof, I saw it could be viewed as a surprising equality between the KL divergence on probabilities and on ratios.
            <br><br>
            I was sure this couldn't be true in general; but why? I worked through the case of a general divergence, trying to find out the line where the proof would break.
            <br><br>
            Half an hour later, after staring at my working multiple times, I was still incredulous that everything seemed to work in general, too. And so was Lemma 2 born. [<a href="javascript:;" onclick="hideDiv('liner_density');">hide</a>]            
            </p>            
          </div>

  <br><br>

  <li> <b>Practical linear models for large-scale one-class collaborative filtering.</b><br>
  Suvash Sedhain, Hung Bui, Jaya Kawale, Nikos Vlassis, Branislav Kveton, Aditya Krishna Menon, Trung Bui and Scott Sanner.<br>
  In <i>International Joint Conference on Artificial Intelligence (<b>IJCAI</b>)</i>, New York City, 2016.<br>
  [<a href="papers/lrec-low/lrec-low-paper.pdf">pdf</a>]

  <br><br>

  <li> <b> On the effectiveness of linear models for one-class collaborative filtering.</b><br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Darius Braziunas.<br>
  In <i>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, Phoenix, 2016.<br>
  [<a href="papers/lrec/lrec-paper.pdf">pdf</a>] [<a href="papers/lrec/lrec-slides.pdf">slides</a>] [<a href="https://github.com/mesuvash/LRec">code</a>]

  <br><br>

  <hr>

  <h3>2015</h3>

  <li> <b>Learning with symmetric label noise: the importance of being unhinged.</b><br>
  Brendan van Rooyen, Aditya Krishna Menon and Robert C. Williamson.<br>
  In <i>Advances in Neural Processing Systems (<b>NIPS</b>)</i>, Montreal, 2015.<br>
  [<a href="papers/unhinged/unhinged-paper.pdf">pdf</a>] [<a href="papers/unhinged/unhinged-poster.pdf">poster</a>]

  <br><br>

  <li> <b>Fine-grained OD estimation with automated zoning and sparsity regularisation.</b><br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.<br>
  In <i><b>Transportation Research Part B: Methodological</b></i>, Volume 80, October 2015, Pages 150-172.<br>
  [<a href="papers/od-estimation/od-estimation-journal-paper.pdf">pdf</a>]

  <br><br>

  <li> <b>Learning from corrupted binary labels via class-probability estimation.</b><br>
  Aditya Krishna Menon, Brendan van Rooyen, Cheng Soon Ong and Robert C. Williamson.<br>
  In <i>International Conference on Machine Learning (<b>ICML</b>)</i>, Lille, 2015.<br>
  [<a href="papers/corrupted-labels/corrupted-labels-paper.pdf">pdf</a>] [<a href="papers/corrupted-labels/corrupted-labels-slides.pdf">slides</a>] [<a href="papers/corrupted-labels/corrupted-labels-poster.pdf">poster</a>] [<a href="papers/corrupted-labels/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_corrupt');">liner notes</a>]  

          <div id="liner_corrupt" style="display:none">
            <br>
            <p style='color:gray'>
            Ever since I read Elkan and Noto's <a href=https://dl.acm.org/citation.cfm?id=1401920>2008 paper on PU learning</a>, I was fascinated by the topic and their approach; I also felt like I didn't fully grok either, since their sample-selection bias viewpoint was unfamiliar to me. I was inspired to rectify this deficiency on my part when reading one of <a href=http://proceedings.mlr.press/v45/Christoffel15.pdf>du Plessis and Sugiyama's elegant papers</a> that extended this work, and crisply stated the problem in terms of the distributions the underlying samples are drawn from.
            <br><br>
            Around the same time, I also stumbled upon some beautiful works on label noise, notably those of <a href=http://proceedings.mlr.press/v30/Scott13.html>Scott et al.</a> and <a href=https://papers.nips.cc/paper/5073-learning-with-noisy-labels.pdf>Natarajan et al.</a>
            I was struck by the apparent similarity of the two problems, but still couldn't quite decipher the apparently different approaches taken to solve them.
            <br><br>
            At this stage, I sought to clarify in my mind how precisely these different problems relate. Which, as is my wont, involved thinking about them in terms of class-probabilities. On discussing ideas with colleagues at NICTA (serendipitously interested in very similar problems), soon enough we ended up writing this paper. [<a href="javascript:;" onclick="hideDiv('liner_corrupt');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <b>AutoRec: autoencoders meet collaborative filtering.</b><br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Lexing Xie.<br>
  In <i>International World Wide Web Conference (<b>WWW</b>)</i>, Florence, 2015.<br>
  [<a href="papers/autorec/autorec-paper.pdf">pdf</a>] [<a href="https://github.com/mesuvash/NNRec">code</a>] [<a href="papers/autorec/autorec-poster.pdf">poster</a>]
  <br><br>

  <li> <b>Cross-modal retrieval: a pairwise classification approach.</b><br>
  Aditya Krishna Menon, Didi Surian and Sanjay Chawla.<br>
  In <i>SIAM Conference on Data Mining (<b>SDM</b>)</i>, Vancouver, 2015.<br>
  [<a href="papers/cross-modal/cross-modal-paper.pdf">pdf (with supplementary)</a>] [<a href="papers/cross-modal/cross-modal-slides.pdf">slides</a>] [<a href="papers/cross-modal/index.html">code</a>]
  <br><br>

  <li> <b>An approach to sparse, fine-grained OD estimation.</b><br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.<br>
  In <i>94th Annual Meeting of the Transporation Research Board (<b>TRB</b>)</i>, Washington DC, 2015.<br>
  [<a href="papers/od-estimation/od-estimation-paper.pdf">pdf</a>] [<a href="papers/od-estimation/od-estimation-poster.pdf">poster</a>]
  <br><br>

  <hr>

  <h3>2014</h3>

  <li> <b>Bayes-optimal scorers for bipartite ranking.</b><br>
  Aditya Krishna Menon and Robert C. Williamson.<br>
  In <i>Conference on Learning Theory (<b>COLT</b>)</i>, Barcelona, 2014.<br>
  [<a href="http://jmlr.org/proceedings/papers/v35/menon14.html">pdf</a>] [<a href="papers/bipartite/bipartite-slides.pdf">slides</a>] [<a href="papers/bipartite/bipartite-poster.pdf">poster</a>]
  <br><br>

  <li> <b>Inappropriate access detection for electronic health records using collaborative filtering.</b><br>
  Aditya Krishna Menon, Xiaoqian Jiang, Jihoon Kim, Lucila Ohno-Machado, and Jaideep Vaidya.<br>
  In <b><i>Machine Learning</i></b>, Volume 95 Number 1, Special Issue on Machine Learning for Society</i></b>, 2014.<br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5376-1">pdf</a>]
  <br><br>

  <hr>

  <h3>2013</h3>

  <li> <b>A colorful approach to text processing by example.</b><br>
  Kuat Yessenov, Shubham Tulsiani, Aditya Krishna Menon, Robert C. Miller, Sumit Gulwani, Butler Lampson, and Adam Kalai.
  <br>In <i>ACM Symposium on User Interface Software and Technology (<b>UIST</b>)</i>, 2013.<br>
  [<a href="http://dl.acm.org/citation.cfm?id=2502040">pdf</a>]
  <br><br>

  <li> <b>Beam search algorithms for multilabel learning.</b><br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.<br>
  In <b><i>Machine Learning</i></b>, 2013.<br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5371-6">pdf</a>]
  <br><br>

  <li> <b>On the statistical consistency of algorithms for binary classification under class imbalance.</b><br>
  Aditya Krishna Menon, Harikrishna Narasimhan, Shivani Agarwal and Sanjay Chawla.<br>
  In <i>International Conference on Machine Learning (<b>ICML</b>)</i>, Atlanta, 2013.<br>
  [<a href="http://jmlr.org/proceedings/papers/v28/menon13a.pdf">pdf</a>] [<a href="papers/imbalance/imbalance-slides.pdf">slides</a>]
  <br><br>

  <li> <b>A machine learning framework for programming by example.</b><br>
  Aditya Krishna Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, and Adam Tauman Kalai.<br>
  In <i>International Conference on Machine Learning (<b>ICML</b>)</i>, Atlanta, 2013.<br>
  [<a href="http://jmlr.csail.mit.edu/proceedings/papers/v28/menon13.pdf">pdf</a>] [<a href="papers/pbe/pbe-poster.pdf">poster</a>] [<a href="papers/pbe/index.html">data</a>]
  <br><br>

  <hr>

  <h3>2012</h3>

  <li> <b>Learning and inference in Probabilistic Classifier Chains with beam search.</b><br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.<br>
  In <i>Machine Learning and Knowledge Discovery in Databases - European Conference (<b>ECML-PKDD</b>), Proceedings Part I</i>, 2012.<br>
  [<a href="http://www.springerlink.com/content/m71407113726156x/">pdf</a>]
  <br><br>

  <li> <b>Doubly optimized calibrated Support Vector Machine (DOC-SVM): an algorithm for joint optimization of discrimination and calibration.</b><br>
  Xiaoqian Jiang, Aditya Krishna Menon, Shuang Wang, Jihoon Kim, and Lucila Ohno-Machado.<br>
  In <b><i>PLoS ONE</b></i>, 7(11): e48823, 2012.<br>
  [<a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048823">pdf</a>] 
  <br><br>

  <li> <b>Predicting accurate probabilities with a ranking loss.</b><br>
  Aditya Krishna Menon, Xiaoqian Jiang, Shankar Vembu, Charles Elkan, and Lucila Ohno-Machado.<br>
  In <i>International Conference on Machine Learning (<b>ICML</b>)</i>, Edinburgh, 2012.<br>
  [<a href="http://icml.cc/2012/papers/372.pdf">pdf</a>] [<a href="papers/calibration/calibration-poster.pdf">poster</a>] [<a href="papers/calibration/index.html">code</a>]
  <br><br>

  <hr>

  <h3>2011</h3>

  <li> <b>Link prediction via matrix factorization.</b><br>
  Aditya Krishna Menon, Charles Elkan.<br>
  In <i>Machine Learning and Knowledge Discovery In Databases - European Conference,
  <b>ECML-PKDD</b>, Proceedings Part II</i>, 2011.<br>
  [<a href="http://www.springerlink.com/content/h1041601305807n0">pdf</a>] [<a href="papers/link-prediction/link-prediction-poster.pdf">poster</a>] [<a href="papers/link-prediction/index.html">code</a>]
  <br><br>

  <li> <b>Response prediction using collaborative filtering with hierarchies and side-information.</b><br>
  Aditya Krishna Menon, Krishna-Prasad Chitrapura, Sachin Garg, Deepak Agarwal, and Nagaraj Kota.<br>
  In <i>Knowledge Discovery and Data Mining (<b>KDD</b>)</i>, San Diego, 2011.<br>
  [<a href="papers/response-prediction/response-prediction-paper.pdf">pdf</a>] [<a href="papers/response-prediction/response-prediction-slides.pdf">slides</a>] [<a href="papers/response-prediction/response-prediction-poster.pdf">poster</a>] [<a href="papers/response-prediction/code.zip">code</a>]
  <br><br>

  <hr>

  <h3>2010</h3>

  <li> <b>Fast algorithms for approximating the singular value decomposition.</b><br>
  Aditya Krishna Menon, Charles Elkan.<br>
  In <i>Transactions of Knowledge and Data Discovery: Special Issue on Large-Scale Data Mining (<b>TKDD-LDMTA</b>)</i>, 2010.<br>
  [<a href="http://dl.acm.org/citation.cfm?id=1921639">pdf</a>] [<a href="papers/code-fastsvd.zip">code</a>]
  <br><br>

  <li> <b>A log-linear model with latent features for dyadic prediction.</b><br>
  Aditya Krishna Menon, Charles Elkan.<br>
  In <i>International Conference on Data Mining (<b>ICDM</b>)</i>, Sydney, 2010.<br>
  [<a href="papers/lfl/lfl-paper.pdf">pdf</a>] [<a href="papers/lfl/lfl-slides.pdf">slides</a>] [<a href="papers/lfl/index.html">code</a>]
  <br><br>

  <li> <b>Predicting labels for dyadic data.</b><br>
  Aditya Krishna Menon, Charles Elkan.<br>
  In <i><b>Data Mining and Knowledge Discovery</b></i>, Special Issue on Papers from <b>ECML-PKDD</b></i> Volume 21, Number 2, 2010.<br>
  [<a href="http://www.springerlink.com/content/115p058437104h7k/fulltext.pdf">pdf</a>] [<a href="papers/labels-dyadic/labels-dyadic-slides.pdf">slides</a>]
  <br><br>

  <hr>

  <h3>2009</h3>

  <li> <b>Large-scale Support Vector Machines: algorithms and theory.</b><br>
  Aditya Krishna Menon.<br>
  Research Exam, University of California, San Diego. 2009.<br>
  [<a
  href="papers/research-exam/research-exam-paper.pdf">pdf</a>] [<a href="papers/research-exam/research-exam-slides.pdf">slides</a>]
  <br><br>

  <hr>

  <h3>2007</h3>

  <li> <b>An incremental data-stream sketch using sparse random projections.</b><br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.<br>
  In <i>SIAM Conference on Data Mining (<b>SDM</b>)</i>, Minnesota, 2007.<br>
  [<a href="papers/random-projections/random-projections-paper.pdf">pdf</a>]
  <br><br>

  <li> <b>An incremental data-stream sketch using sparse random projections.</b><br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.<br>
  Technical Report 609, University of Sydney. 2007.<br>
  [<a href="papers/random-projections/random-projections-tr-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2006</h3>

  <li> <b>Random projections and applications to dimensionality reduction.</b><br>
  Aditya Krishna Menon.<br>
  Honours thesis, University of Sydney. 2006.<br>
  [<a href="papers/honours/honours-thesis.pdf">pdf</a>] [<a href="papers/honours/honours-slides.pdf">slides</a>]

  </ul>
  </div>

</div>

</body>

</html>
